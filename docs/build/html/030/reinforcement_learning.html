

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Reinforcement Learning &mdash; RDB2G-Bench 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=2709fde1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="LLM-based Baseline" href="llm_baseline.html" />
    <link rel="prev" title="Bayesian Optimization" href="bayesian_optimization.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            RDB2G-Bench
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../010/install_and_setup.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../010/tutorial.html">Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../020/download_precomputed.html">Download Pre-computed Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../020/reproduce_datasets.html">Reproduce Datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="micro_action.html">Micro Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="run_benchmark.html">Run Benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="random_search.html">Random Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="greedy_search.html">Greedy Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="evolutionary_algorithm.html">Evolutionary Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_optimization.html">Bayesian Optimization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#how-it-works">How it Works</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rdb2g_bench.benchmark.baselines.rl">Reinforcement Learning Baseline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rdb2g_bench.benchmark.baselines.rl.ControllerRNN"><code class="docutils literal notranslate"><span class="pre">ControllerRNN</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#rdb2g_bench.benchmark.baselines.rl.ControllerRNN.forward"><code class="docutils literal notranslate"><span class="pre">ControllerRNN.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rdb2g_bench.benchmark.baselines.rl.ControllerRNN.init_hidden"><code class="docutils literal notranslate"><span class="pre">ControllerRNN.init_hidden()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rdb2g_bench.benchmark.baselines.rl.apply_action"><code class="docutils literal notranslate"><span class="pre">apply_action()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#rdb2g_bench.benchmark.baselines.rl.get_action_space"><code class="docutils literal notranslate"><span class="pre">get_action_space()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#rdb2g_bench.benchmark.baselines.rl.get_state_embedding"><code class="docutils literal notranslate"><span class="pre">get_state_embedding()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#rdb2g_bench.benchmark.baselines.rl.rl_heuristic_analysis"><code class="docutils literal notranslate"><span class="pre">rl_heuristic_analysis()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-usage">Example Usage</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="llm_baseline.html">LLM-based Baseline</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">RDB2G-Bench</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Reinforcement Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/030/reinforcement_learning.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="reinforcement-learning">
<h1>Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Link to this heading"></a></h1>
<p>This module implements reinforcement learning baseline for neural architecture search.
The approach uses deep reinforcement learning with policy gradients to train
a recurrent neural network controller that learns to generate sequences of micro actions
for constructing high-performing graph neural network architectures.</p>
<section id="how-it-works">
<h2>How it Works<a class="headerlink" href="#how-it-works" title="Link to this heading"></a></h2>
<p>The reinforcement learning process:</p>
<ol class="arabic simple">
<li><p>Initialize RNN-based controller to learn graph construction actions</p></li>
<li><p>Start from random graph construction and convert to state embedding</p></li>
<li><p>Controller selects actions</p></li>
<li><p>Evaluate performance of new graph construction and compute reward</p></li>
<li><p>Update controller policy using Policy Gradient based on discounted rewards</p></li>
<li><p>Repeat episodes until budget is exhausted</p></li>
</ol>
</section>
<section id="module-rdb2g_bench.benchmark.baselines.rl">
<span id="reinforcement-learning-baseline"></span><h2>Reinforcement Learning Baseline<a class="headerlink" href="#module-rdb2g_bench.benchmark.baselines.rl" title="Link to this heading"></a></h2>
<p>RDB2G-Bench Reinforcement Learning Baseline Module</p>
<p>This module implements reinforcement learning for neural architecture search on RDB2G-Bench.
The approach uses a recurrent neural network controller that learns to generate sequences
of micro actions to construct high-performing graph neural network architectures.</p>
<p>The reinforcement learning approach can learn complex policies for architecture
construction by exploring the space of micro action sequences.</p>
<dl class="py class">
<dt class="sig sig-object py" id="rdb2g_bench.benchmark.baselines.rl.ControllerRNN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">rdb2g_bench.benchmark.baselines.rl.</span></span><span class="sig-name descname"><span class="pre">ControllerRNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lstm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rdb2g_bench.benchmark.baselines.rl.ControllerRNN" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Recurrent Neural Network Controller for Architecture Search.</p>
<p>This controller generates sequences of actions to construct graph neural network
architectures. It uses either LSTM or GRU cells to maintain state across the
action sequence and outputs action probabilities for policy gradient training.</p>
<dl>
<dt>Attributes:</dt><dd><p>hidden_dim (int): Hidden dimension of the RNN
num_layers (int): Number of RNN layers
rnn_type (str): Type of RNN cell (‘lstm’ or ‘gru’)
rnn (nn.Module): The RNN module (LSTM or GRU)
action_head (nn.Linear): Linear layer for action probability output</p>
</dd>
<dt>Args:</dt><dd><p>input_dim (int): Dimensionality of input state embeddings
hidden_dim (int): Hidden dimension of the RNN
num_actions (int): Number of possible actions in the action space
rnn_type (str): Type of RNN to use (‘lstm’ or ‘gru’). Defaults to ‘lstm’.
num_layers (int): Number of RNN layers. Defaults to 1.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">controller</span> <span class="o">=</span> <span class="n">ControllerRNN</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">num_actions</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">rnn_type</span><span class="o">=</span><span class="s1">&#39;lstm&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">state_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hidden</span> <span class="o">=</span> <span class="n">controller</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">action_logits</span><span class="p">,</span> <span class="n">new_hidden</span> <span class="o">=</span> <span class="n">controller</span><span class="p">(</span><span class="n">state_emb</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="rdb2g_bench.benchmark.baselines.rl.ControllerRNN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rdb2g_bench.benchmark.baselines.rl.ControllerRNN.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the controller.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>state_embedding (torch.Tensor): Current state embedding of shape (batch, seq, input_dim)
hidden_state (tuple or torch.Tensor): Hidden state from previous step</p>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>tuple: (action_logits, new_hidden_state)</dt><dd><ul class="simple">
<li><p>action_logits: Logits for action selection of shape (batch, num_actions)</p></li>
<li><p>new_hidden_state: Updated hidden state</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="rdb2g_bench.benchmark.baselines.rl.ControllerRNN.init_hidden">
<span class="sig-name descname"><span class="pre">init_hidden</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rdb2g_bench.benchmark.baselines.rl.ControllerRNN.init_hidden" title="Link to this definition"></a></dt>
<dd><p>Initialize hidden state for the RNN.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>batch_size (int): Batch size for initialization</p>
</dd>
<dt>Returns:</dt><dd><p>tuple or torch.Tensor: Initial hidden state</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="rdb2g_bench.benchmark.baselines.rl.apply_action">
<span class="sig-prename descclassname"><span class="pre">rdb2g_bench.benchmark.baselines.rl.</span></span><span class="sig-name descname"><span class="pre">apply_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">current_edge_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_details</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">micro_action_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="micro_action.html#rdb2g_bench.benchmark.micro_action.MicroActionSet" title="rdb2g_bench.benchmark.micro_action.MicroActionSet"><span class="pre">MicroActionSet</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rdb2g_bench.benchmark.baselines.rl.apply_action" title="Link to this definition"></a></dt>
<dd><p>Apply the selected action to transition to a new architecture state.</p>
<p>This function executes the chosen micro action and returns the resulting
edge set configuration and its index in the valid edge sets list.</p>
<dl>
<dt>Args:</dt><dd><p>current_edge_set (tuple): Current binary edge set representation
action_details (dict): Action specification with ‘type’ and ‘target_index’
micro_action_set (MicroActionSet): Set of available micro actions</p>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>tuple: (new_edge_set, new_index)</dt><dd><ul class="simple">
<li><p>new_edge_set: Resulting edge set after action application</p></li>
<li><p>new_index: Index of new edge set in valid_edge_sets_list</p></li>
</ul>
</dd>
</dl>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">action</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;add_fk_pk&quot;</span><span class="p">,</span> <span class="s2">&quot;target_index&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_set</span><span class="p">,</span> <span class="n">new_idx</span> <span class="o">=</span> <span class="n">apply_action</span><span class="p">(</span><span class="n">current_set</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">micro_actions</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="rdb2g_bench.benchmark.baselines.rl.get_action_space">
<span class="sig-prename descclassname"><span class="pre">rdb2g_bench.benchmark.baselines.rl.</span></span><span class="sig-name descname"><span class="pre">get_action_space</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">micro_action_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="micro_action.html#rdb2g_bench.benchmark.micro_action.MicroActionSet" title="rdb2g_bench.benchmark.micro_action.MicroActionSet"><span class="pre">MicroActionSet</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_edge_set</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rdb2g_bench.benchmark.baselines.rl.get_action_space" title="Link to this definition"></a></dt>
<dd><p>Determine valid actions from the current architecture state.</p>
<p>This function analyzes the current edge set and returns all possible
micro actions that can be applied, along with a special stop action.</p>
<dl>
<dt>Args:</dt><dd><p>micro_action_set (MicroActionSet): Set of available micro actions
current_edge_set (tuple): Current binary edge set representation</p>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>tuple: (possible_actions_with_ids, num_total_valid_actions)</dt><dd><ul class="simple">
<li><p>possible_actions_with_ids: List of (action_detail, action_id) tuples</p></li>
<li><p>num_total_valid_actions: Total number of available actions including stop</p></li>
</ul>
</dd>
</dl>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">actions</span><span class="p">,</span> <span class="n">num_actions</span> <span class="o">=</span> <span class="n">get_action_space</span><span class="p">(</span><span class="n">micro_actions</span><span class="p">,</span> <span class="n">current_set</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Available actions: </span><span class="si">{</span><span class="n">num_actions</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="rdb2g_bench.benchmark.baselines.rl.get_state_embedding">
<span class="sig-prename descclassname"><span class="pre">rdb2g_bench.benchmark.baselines.rl.</span></span><span class="sig-name descname"><span class="pre">get_state_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">current_edge_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rdb2g_bench.benchmark.baselines.rl.get_state_embedding" title="Link to this definition"></a></dt>
<dd><p>Convert edge set representation into a fixed-size embedding for RNN input.</p>
<p>This function transforms the binary edge set representation into a padded
or truncated tensor suitable for the RNN controller input.</p>
<dl>
<dt>Args:</dt><dd><p>current_edge_set (tuple or list): Binary representation of active edges
embedding_dim (int): Target dimensionality for the embedding</p>
</dd>
<dt>Returns:</dt><dd><p>torch.Tensor: State embedding of shape (1, 1, embedding_dim)</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">edge_set</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span> <span class="o">=</span> <span class="n">get_state_embedding</span><span class="p">(</span><span class="n">edge_set</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">torch.Size([1, 1, 8])</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="rdb2g_bench.benchmark.baselines.rl.rl_heuristic_analysis">
<span class="sig-prename descclassname"><span class="pre">rdb2g_bench.benchmark.baselines.rl.</span></span><span class="sig-name descname"><span class="pre">rl_heuristic_analysis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PerformancePredictionDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">micro_action_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="micro_action.html#rdb2g_bench.benchmark.micro_action.MicroActionSet" title="rdb2g_bench.benchmark.micro_action.MicroActionSet"><span class="pre">MicroActionSet</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">overall_actual_y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">higher_is_better</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">controller_rnn_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'lstm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">controller_num_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">controller_hidden_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_episodes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_steps_per_episode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">termination_threshold_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'RL</span> <span class="pre">Heuristic</span> <span class="pre">(Policy</span> <span class="pre">Gradient)'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#rdb2g_bench.benchmark.baselines.rl.rl_heuristic_analysis" title="Link to this definition"></a></dt>
<dd><p>Perform Neural Architecture Search using Reinforcement Learning with Policy Gradients.</p>
<p>This function implements a complete RL-based search using REINFORCE algorithm.
An RNN controller learns to generate sequences of micro actions that construct
high-performing graph neural network architectures.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>dataset (PerformancePredictionDataset): Dataset containing architecture </dt><dd><p>performance data</p>
</dd>
<dt>micro_action_set (MicroActionSet): Set of micro actions for architecture</dt><dd><p>space exploration</p>
</dd>
<dt>overall_actual_y (torch.Tensor): Complete performance tensor for</dt><dd><p>ranking calculations</p>
</dd>
</dl>
<p>higher_is_better (bool): Whether higher performance values are better
controller_rnn_type (str): RNN type for controller (‘lstm’ or ‘gru’).</p>
<blockquote>
<div><p>Defaults to ‘lstm’.</p>
</div></blockquote>
<p>controller_num_layers (int): Number of RNN layers. Defaults to 1.
controller_hidden_dim (int): Hidden dimension of controller RNN.</p>
<blockquote>
<div><p>Defaults to 32.</p>
</div></blockquote>
<dl class="simple">
<dt>learning_rate (float): Learning rate for controller optimization.</dt><dd><p>Defaults to 0.005.</p>
</dd>
</dl>
<p>num_episodes (int): Number of RL episodes to run. Defaults to 50.
max_steps_per_episode (int): Maximum steps per episode. Defaults to 5.
gamma (float): Discount factor for returns computation. Defaults to 0.99.
termination_threshold_ratio (float): Fraction of total architectures to</p>
<blockquote>
<div><p>evaluate as budget. Defaults to 0.1.</p>
</div></blockquote>
<dl class="simple">
<dt>method_name (str): Name identifier for this method. </dt><dd><p>Defaults to “RL Heuristic (Policy Gradient)”.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>Dict: Comprehensive results dictionary containing:</dt><dd><ul class="simple">
<li><p>method: Method name</p></li>
<li><p>selected_graph_id: Index of best found architecture</p></li>
<li><p>actual_y_perf_of_selected: Performance of selected architecture</p></li>
<li><p>selection_metric_value: Metric value used for selection</p></li>
<li><p>selected_graph_origin: Origin method name</p></li>
<li><p>discovered_count: Number of architectures evaluated</p></li>
<li><p>total_iterations_run: Number of episodes completed</p></li>
<li><p>rank_position_overall: Rank among all architectures</p></li>
<li><p>percentile_overall: Percentile ranking</p></li>
<li><p>total_samples_overall: Total available architectures</p></li>
<li><p>performance_trajectory: Performance over time</p></li>
<li><p>total_evaluation_time: Time spent on evaluations</p></li>
<li><p>total_run_time: Total algorithm runtime</p></li>
</ul>
</dd>
</dl>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">rl_heuristic_analysis</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">micro_action_set</span><span class="o">=</span><span class="n">micro_actions</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">overall_actual_y</span><span class="o">=</span><span class="n">y_tensor</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">higher_is_better</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">controller_rnn_type</span><span class="o">=</span><span class="s1">&#39;lstm&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">controller_hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">num_episodes</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_steps_per_episode</span><span class="o">=</span><span class="mi">10</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best architecture: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;selected_graph_id&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Performance: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;actual_y_perf_of_selected&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<section id="example-usage">
<h3>Example Usage<a class="headerlink" href="#example-usage" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">rdb2g_bench.benchmark.runner</span><span class="w"> </span><span class="kn">import</span> <span class="n">run_benchmark</span>

<span class="c1"># Run reinforcement learning with default parameters</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">run_benchmark</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;rel-f1&quot;</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="s2">&quot;driver-top3&quot;</span><span class="p">,</span>
    <span class="n">budget_percentage</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;rl&quot;</span><span class="p">],</span>
    <span class="n">num_runs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Access results</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best architecture found: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;rl&#39;</span><span class="p">][</span><span class="s1">&#39;selected_graph_id&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Performance: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;rl&#39;</span><span class="p">][</span><span class="s1">&#39;actual_y_perf_of_selected&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Episodes completed: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;rl&#39;</span><span class="p">][</span><span class="s1">&#39;total_iterations_run&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="bayesian_optimization.html" class="btn btn-neutral float-left" title="Bayesian Optimization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="llm_baseline.html" class="btn btn-neutral float-right" title="LLM-based Baseline" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright KAIST Data Mining Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>